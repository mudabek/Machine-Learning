{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mcmc_decoder",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMhTUId7kD7Q"
      },
      "source": [
        "# MADE Advanced ML \n",
        "## Homework 3 : Interpreting Coded Text\n",
        "### Otabek Nazarov"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTTVQm9yjjr_"
      },
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "import pdb\n",
        "import zipfile\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SFL01OFkrUm"
      },
      "source": [
        "# load the needed files\n",
        "! wget https://www.dropbox.com/s/k23enjvr3fb40o5/corpora.zip  -nc\n",
        "\n",
        "with zipfile.ZipFile('corpora.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVrs0aPCk6a_"
      },
      "source": [
        "with open('WarAndPeace.txt') as f:\n",
        "    war_peace_rus = f.read()\n",
        "\n",
        "with open('WarAndPeaceEng.txt') as f:\n",
        "    war_peace_eng = f.read()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB72qwOiB9rq"
      },
      "source": [
        "## 1. Basic Frequency Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0TKVX3em_4Y"
      },
      "source": [
        "# russian tokens for decoding\n",
        "rus_tokens = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя '\n",
        "\n",
        "def is_in_tokens(token, tokens_list):\n",
        "    if token not in tokens_list:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def tokens_only(text, tokens_list):\n",
        "    l = text.split()\n",
        "    l = list(filter(lambda s:all([is_in_tokens(c, tokens_list) for c in s]), l))\n",
        "    return ' '.join(l)\n",
        "\n",
        "def process_text(text, tokens):\n",
        "    # remove punctuation and turn letters into lower case\n",
        "    table = str.maketrans(dict.fromkeys(string.punctuation))\n",
        "    text = text.translate(table).lower()\n",
        "    text = tokens_only(text, tokens)\n",
        "    text = re.sub('\\s+',' ', text)\n",
        "    return text\n",
        "\n",
        "def get_freq_map(text, tokens):\n",
        "    # create a frequency mapping for a given text\n",
        "    text = process_text(text, tokens)\n",
        "    char_freq_map = Counter(text)\n",
        "    return char_freq_map\n",
        "\n",
        "def mix_and_map_tokens(text, tokens):\n",
        "    # get present characters and shuffle them as well\n",
        "    random.seed(1)\n",
        "    tokens_shuffled = ''.join(random.sample(tokens,len(tokens)))\n",
        "    shuffle_map = {}\n",
        "\n",
        "    # creating mapping dictionary for shuffled characters\n",
        "    for i in range(len(tokens)):\n",
        "        shuffle_map[tokens[i]] = tokens_shuffled[i]\n",
        "    return shuffle_map\n",
        "\n",
        "def shuffle_text(text, tokens):\n",
        "    # get shuffled mapping of characters\n",
        "    shuffle_map = mix_and_map_tokens(text, tokens)\n",
        "\n",
        "    # create a new text based on shuffling\n",
        "    changed_text = ''\n",
        "    for c in text:\n",
        "        changed_text += shuffle_map[c]\n",
        "    \n",
        "    return changed_text\n",
        "\n",
        "def naive_unigram_decode(test_text, dictionary_text, tokens):\n",
        "    # shuffle list and get its frequency mapping\n",
        "    shuffled_text = test_text\n",
        "    test_freq = get_freq_map(shuffled_text, tokens).most_common(len(set(test_text)))\n",
        "    # get frequency mapping of dictionary text\n",
        "    dict_text_freq = get_freq_map(dictionary_text, tokens).most_common(len(test_freq))\n",
        "\n",
        "    # match characters based on frequency\n",
        "    char_interp_map = {}\n",
        "    for i in range(len(test_freq)):\n",
        "        char_interp_map[test_freq[i][0]] = dict_text_freq[i][0]\n",
        "\n",
        "    # decode the shuffled text\n",
        "    decoded = ''\n",
        "    for c in shuffled_text:\n",
        "        decoded += char_interp_map[c]\n",
        "    \n",
        "    return decoded\n",
        "\n",
        "def get_accuracy(predict, target):\n",
        "    correct_count = 0\n",
        "    for i in range(len(predict)):\n",
        "        if predict[i] == target[i]:\n",
        "            correct_count += 1\n",
        "    return correct_count / len(predict)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG8ABIxpSXQR"
      },
      "source": [
        "original_test_text = process_text(war_peace_rus[12314:13500], rus_tokens)\n",
        "test_text = shuffle_text(original_test_text, rus_tokens)\n",
        "decoded = naive_unigram_decode(test_text, war_peace_rus, rus_tokens)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "oT8-Sb6qPMbS",
        "outputId": "aee3c19e-a7ff-4864-b9ff-f54ca8d2e43a"
      },
      "source": [
        "test_text"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ъм кзвэзэвшлрчкваычвамёв кзъм кзвомыч чыясвшмэмёчъшвмызвимъмрчёвхзалщллвлвдмгзкзвп нвекмваычвытьымвлвмыв вкчалв пмдмоыюалвлвхзалщясъыюалвгъзблмуыюалвопльчылсалвэмкмъючвчгмвмкщлезщлвпусщвузвътэтвхъчёщлытвшмбчщмпзщвччвлвшмбчщмпзпвшмазизщвхъчёщлы эмйвътэмёвъзупзщлпрл явызвэъч щзивлвгщсосвпв кмъмытвшмомьолкчв эзузщзвзыызвшзпщмпызв ммдъзьзсвсвыюыечвьчвшмгмпмъйвдмщэмы элёв вщлумёвьчымёвамщмомгмвдмщэмы эмгмвлвамьчквдюкявцкмвтщзолк свсвпвпзрчав чачё кпчвызеытвмдтезкя свъчач щтв кзъмёвочпэлвгм клызсвзыыювшзпщмпыювызезщзвшмычаымгтвызшмщыскя свшълчизщзвпю рзсвуызкявшчкчъдтъгзвщйолв заючвъзуымъмоыючвшмвпмуъз кзавлвизъзэкчъзавымвмолызэмпючвшмвмдфч кптвпвэзэмавп чвьлщлвшълчизщзвомеявэысусвпз лщлсвэъз зплбзвцщчывузчизпрзсвузвмкбмавекмдюв вылавпач кчвчизкявызвшъзуоылэвшм щзыылэзвмызвдющзвпврлхъчвлвдзщяымавшщзкячвшълчизщзвлвлупч кызсвэзэв зазсвмдпмъмьлкчщяызсвьчыфлызвпвшчкчъдтъгчвамщмозсвазщчыяэзсвэысглысвдмщэмы эзсвшъмрщтйвулатвпюрчорзсвузатьвлвкчшчъя'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "WcHFWHIWSXQR",
        "outputId": "fb905813-91b8-42b8-bd4d-be5a62ed49ab"
      },
      "source": [
        "decoded"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ласво дод унжев кие кач своласво яаиесеизм уадачелу аио шалажеч юокнтнн н ьабово рсё хва кие ипйиа н аи с векн сраьаяиыкн н юокнтзмлиыкн блоцнагиыкн ярнйеинмкн давалые еба автнхотн ргмт го лпдп юлечтнип уацетарот ее н уацетарор уакошот юлечтнисдаэ лпдач логротнржнсз ио длестош н бтмям р свалаип уаяайянве сдогото оиио уортарио сааьлойом м иыихе йе уабаралэ ьатдаисднч с тнгач йеиач катаяаба ьатдаисдаба н кайев ьывз щва птоянвсм м р рожек секечсвре иохип аьпховзсм лекестп сволач яердн басвниом оииы уортариы иохото уаиекиабп иоуатимвзсм улнешото рысжом гиовз уевельплбо тэян сокые логиалаяиые уа раглосвок н шолодвелок иа аяниодарые уа аьфесврп р додак рсе йнтн улнешото яахз димгм роснтнм длосорнцо щтеи гоешоржом го авцак хваьы с инк ркесве ешовз ио улогяинд уастоииндо аио ьыто р жнюле н ьотзиак утовзе улнешото н нгресвиом дод соком аьралайнветзиом йеифнио р уевельплбе катаяом котеиздом димбним ьатдаисдом улажтпэ гнкп рыжеяжом гокпй н веуелз'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTUZ05w9WXa2",
        "outputId": "338007c3-e68f-45c1-f630-e7ebbe793ff7"
      },
      "source": [
        "# unigram accuracy\n",
        "get_accuracy(original_test_text, decoded)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.273972602739726"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz3UfEByTQNS"
      },
      "source": [
        "#### Observations\n",
        "For a given small text sample we are getting low accuracy of 30% and not interpretable text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-7DHxlDCJIN"
      },
      "source": [
        "## 2. Bigram analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_qPy3kvCWwE"
      },
      "source": [
        "def get_ngram_freq_map(text, tokens, n_gram=2):\n",
        "    # create a bigram frequency mapping for a given text\n",
        "    text = process_text(text, tokens)\n",
        "    char_freq_map = Counter(text[idx : idx + n_gram] for idx in range(len(text) - n_gram))\n",
        "    return char_freq_map\n",
        "\n",
        "def interpret_bigram_text(test_text, dictionary_text, tokens):\n",
        "    bigram_counter = get_bigram_freq_map(test_text, tokens)\n",
        "    test_freq = bigram_counter.most_common(len(bigram_counter))\n",
        "    # get frequency mapping of dictionary text\n",
        "    dict_text_freq = get_bigram_freq_map(dictionary_text, tokens).most_common(len(test_freq))\n",
        "\n",
        "    # match characters based on frequency\n",
        "    char_interp_map = {}\n",
        "    for i in range(len(test_freq)):\n",
        "        char_interp_map[test_freq[i][0]] = dict_text_freq[i][0]\n",
        "\n",
        "    # decode the shuffled text\n",
        "    decoded = ' '\n",
        "    for i in range(0, len(test_text) - 1, 2):\n",
        "        decoded += char_interp_map[test_text[i:i+2]]\n",
        "    \n",
        "    return decoded"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPQanmlfGwyD"
      },
      "source": [
        "decoded_bigram = interpret_bigram_text(test_text, war_peace_rus, rus_tokens)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "_IE4HP0fG-at",
        "outputId": "8696b17d-ce9a-4307-f1dd-93e6a664da5c"
      },
      "source": [
        "decoded_bigram"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' ратоо й льий ривес сде бтомиод твенаенот эи утон муснао шара р бедвоале е заие т вгрейанкаы похоося гобочтовво немзаняеге е едвотиев двою новшму двовеэт часаже станще слуневиалинал вчах к тьоел ныдаал уи дррув  кит се  обеорскре ооберх ныдаалойстс адст бноуд к хляжипоо свень д е ькзьа ретонинал  о зцече согбы ко  а пи аторихо ыву ноеха а  дьн с чи тав нис заимнаогук низиконмоотонкапрлатанезаимнаогтанее де чивтрелсианумь еташа а реск ролаваяепдн с пвлл у ежриожа омаясял томионвеье жю одые па  а ди аторихди пинь и на госялпотнпрдоелиси мен  ко амых или пели ак мматыо гдет нм жетьбыосраняжеи неемг  л толе ерноув мм понелаловав жеи неу лютотс вковале вавмо ее т сеерь вевутезнлка скоиала св латысо  фотлиаюерту илио виушолкну дичтасолссеновитерелпоо т быняыми одь ннымо нао трь  впиоюомя ро кеелеи ь ел ст сеерь я я уденяд икова нм  игосунивсчеруее имоотпл п ви ак мматы сдеоруча обулкий а знпулоа заимнаог ии раирсёлиыйл ам рещ илим хоя ылрт м'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zuul7PHSQG4w",
        "outputId": "b5b23497-1480-4f5c-bd76-d9f5111f29c0"
      },
      "source": [
        "# bigram accuracy\n",
        "get_accuracy(original_test_text, decoded_bigram)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07903055848261328"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elJZzVF5VqoJ"
      },
      "source": [
        "#### Observations\n",
        "Using bigrams produces a worse accuracy compared to using unigrams. Simply using bigrams does not capture the context of the word better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8d6xL5EWyeC"
      },
      "source": [
        "## 3. MCMC-Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qv9qu9az1Hp"
      },
      "source": [
        "I will use the following MCMC based algorithm: <br>\n",
        "\n",
        "1. Start with any random f, say, the identify function that maps a to a, b to b, etc.\n",
        "\n",
        "2. Pick two letters uniformly at random and switch the values that f assigns to these two symbols. Call this proposal state f.\n",
        "\n",
        "3. Compute the score of the new proposed state f. If the state produces better result, accept it as the best score.\n",
        "\n",
        "4. Repeat steps 2-3 until acceptable decoded text is produced\n",
        "\n",
        "As a score we will use the product of all occuring bigram frequencies, which can be interpreted as likelihood. To speed up and simplify the computation we will use the log likelihood.\n",
        "\n",
        "\n",
        "\n",
        "Reference: <br>\n",
        "https://tleise.people.amherst.edu/Math365Spring2014/Labs/DecryptionLab.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8Aibjra1NSP"
      },
      "source": [
        "class MCMC_decoder():\n",
        "    def __init__(self, tokens, dictionary_text, n_gram=2):\n",
        "        self.tokens = tokens\n",
        "        self.n_gram = n_gram\n",
        "        self.freq_mapping = get_ngram_freq_map(dictionary_text, tokens, n_gram)\n",
        "\n",
        "    def _change_text(self, text):\n",
        "        l1 = random.choice(self.tokens)\n",
        "        l2 = random.choice(self.tokens)\n",
        "        new_text = ''\n",
        "        for c in text:\n",
        "            if c == l1:\n",
        "                new_text += l2\n",
        "            elif c == l2:\n",
        "                new_text += l1\n",
        "            else:\n",
        "                new_text += c\n",
        "        return new_text\n",
        "\n",
        "    def _score(self, text):\n",
        "        cur_bigram_mapping = get_ngram_freq_map(text, self.tokens, self.n_gram)\n",
        "        unknown_key_val = 2\n",
        "        sum = 0\n",
        "        for bigram, count in cur_bigram_mapping.items():\n",
        "            sum += count * np.log(self.freq_mapping.get(bigram, unknown_key_val))\n",
        "        return sum\n",
        "\n",
        "    def decode(self, text, n_iter=20000):\n",
        "        best_decoded_text = text\n",
        "        cur_score = self._score(text)\n",
        "        best_score = self._score(text) \n",
        "        for iter in range(n_iter):\n",
        "            new_text = self._change_text(text)\n",
        "            new_score = self._score(new_text)\n",
        "            if cur_score < new_score:\n",
        "                text = new_text\n",
        "                cur_score = new_score\n",
        "                if cur_score > best_score:\n",
        "                    best_score = cur_score\n",
        "                    best_decoded_text = text\n",
        "                   \n",
        "        return best_decoded_text"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0r9OAp6IpPP"
      },
      "source": [
        "mcmc = MCMC_decoder(rus_tokens, war_peace_rus)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "iogtfKgMgzOI",
        "outputId": "8ee44e51-f3a8-4349-b592-b895402b1a59"
      },
      "source": [
        "test_text"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ъм кзвэзэвшлрчкваычвамёв кзъм кзвомыч чыясвшмэмёчъшвмызвимъмрчёвхзалщллвлвдмгзкзвп нвекмваычвытьымвлвмыв вкчалв пмдмоыюалвлвхзалщясъыюалвгъзблмуыюалвопльчылсалвэмкмъючвчгмвмкщлезщлвпусщвузвътэтвхъчёщлытвшмбчщмпзщвччвлвшмбчщмпзпвшмазизщвхъчёщлы эмйвътэмёвъзупзщлпрл явызвэъч щзивлвгщсосвпв кмъмытвшмомьолкчв эзузщзвзыызвшзпщмпызв ммдъзьзсвсвыюыечвьчвшмгмпмъйвдмщэмы элёв вщлумёвьчымёвамщмомгмвдмщэмы эмгмвлвамьчквдюкявцкмвтщзолк свсвпвпзрчав чачё кпчвызеытвмдтезкя свъчач щтв кзъмёвочпэлвгм клызсвзыыювшзпщмпыювызезщзвшмычаымгтвызшмщыскя свшълчизщзвпю рзсвуызкявшчкчъдтъгзвщйолв заючвъзуымъмоыючвшмвпмуъз кзавлвизъзэкчъзавымвмолызэмпючвшмвмдфч кптвпвэзэмавп чвьлщлвшълчизщзвомеявэысусвпз лщлсвэъз зплбзвцщчывузчизпрзсвузвмкбмавекмдюв вылавпач кчвчизкявызвшъзуоылэвшм щзыылэзвмызвдющзвпврлхъчвлвдзщяымавшщзкячвшълчизщзвлвлупч кызсвэзэв зазсвмдпмъмьлкчщяызсвьчыфлызвпвшчкчъдтъгчвамщмозсвазщчыяэзсвэысглысвдмщэмы эзсвшъмрщтйвулатвпюрчорзсвузатьвлвкчшчъя'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90MHlQYJI7Uu",
        "outputId": "901473b3-1818-4ce4-a9bb-4b19bf9ef0bf"
      },
      "source": [
        "mcmc_decoded_text = mcmc.decode(test_text)\n",
        "print(mcmc_decoded_text)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "роста как пишет мне мой староста донесенья покойерп она хорошей фамилии и богата всё что мне нужно и он с теми свободными и фамильярными грациозными движениями которые его отличали взял за руку фрейлину поцеловал ее и поцеловав помахал фрейлинскою рукой развалившись на креслах и глядя в сторону подождите сказала анна павловна соображая я нынче же поговорю болконский с лизой женой молодого болконского и может быть это уладится я в вашем семействе начну обучаться ремеслу старой девки гостиная анны павловны начала понемногу наполняться приехала высшая знать петербурга люди самые разнородные по возрастам и характерам но одинаковые по обществу в каком все жили приехала дочь князя василия красавица элен заехавшая за отцом чтобы с ним вместе ехать на праздник посланника она была в шифре и бальном платье приехала и известная как самая обворожительная женщина в петербурге молодая маленькая княгиня болконская прошлую зиму вышедшая замуж и теперь\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAlmzs7Jg_dT",
        "outputId": "e84a5143-4028-4977-8a73-79bba41e833e"
      },
      "source": [
        "get_accuracy(process_text(war_peace_rus[12314:13500], rus_tokens), mcmc_decoded_text)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szyc7a9shI9t"
      },
      "source": [
        "final_test = '←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBGLYmTBzZgr"
      },
      "source": [
        "def encode(text, tokens):\n",
        "    tokens = list(set(tokens))\n",
        "    text_tokens = list(set(text))\n",
        "    \n",
        "    mapping = {}\n",
        "    for i in range(len(text_tokens)):\n",
        "        mapping[text_tokens[i]] = tokens[i]\n",
        "     \n",
        "    encoded_text = ''\n",
        "    for c in text:\n",
        "        encoded_text += mapping[c]\n",
        "    return encoded_text"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCrqtofcl--Q",
        "outputId": "c0806bd1-c0a0-4605-d6bd-e3f9e282e3a8"
      },
      "source": [
        "mcmc = MCMC_decoder(rus_tokens, war_peace_rus)\n",
        "mcmc_decoded_text = mcmc.decode(encode(final_test, rus_tokens))\n",
        "print(mcmc_decoded_text)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "если вы вимите норжальный или подти норжальный текст у чтого сообщения который легко продитать скорее всего вы все смелали правильно и полудите жаксижальный балл за послемнее детвертое замание курса хотя конедно я нидего не обещаш\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz6R-ldWAYdJ"
      },
      "source": [
        "## 4. MCMC Sampling with Higher N_grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFSzgeUZzOXS",
        "outputId": "4ed99044-119f-4c41-a393-0caac10ccf3f"
      },
      "source": [
        "# n_gram = 3\n",
        "mcmc = MCMC_decoder(rus_tokens, war_peace_rus, n_gram=3)\n",
        "mcmc_decoded_text = mcmc.decode(encode(final_test, rus_tokens))\n",
        "print(mcmc_decoded_text)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "если вы видите норжальный или почти норжальный текст у этого сообщения который легко прочитать скорее всего вы все сделали правильно и получите жаксижальный балл за последнее четвертое задание курса мотя конечно я ничего не обещац\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvCZ0pA-_tZU",
        "outputId": "04fc7b80-5ce1-40d4-c8c0-a3f3d4e35dce"
      },
      "source": [
        "# n_gram = 4\n",
        "mcmc = MCMC_decoder(rus_tokens, war_peace_rus, n_gram=4)\n",
        "mcmc_decoded_text = mcmc.decode(encode(final_test, rus_tokens), n_iter=50000)\n",
        "print(mcmc_decoded_text)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "если вы видите нормальный или почти нормальный текст у этого сообщения который легко прочитать скорее всего вы все сделали правильно и получите максимальный балл за последнее четвертое задание курса хотя конечно я ничего не обещаф\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUB20DGD__UM",
        "outputId": "c1010b88-2236-4e5f-c057-9d139439d283"
      },
      "source": [
        "# n_gram = 5\n",
        "mcmc = MCMC_decoder(rus_tokens, war_peace_rus, n_gram=5)\n",
        "mcmc_decoded_text = mcmc.decode(encode(final_test, rus_tokens), n_iter=1000000)\n",
        "print(mcmc_decoded_text)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "енусм ым состемьрщибудьыёмсусмюратсмьрщибудьыёмтейнтмчмхтрпрмнррфкеьсвмйртрщыёмуепйрмющрастбтдмнйрщеем непрм ым немноеубусмющб судьрмсмюручастемибйнсибудьыёмфбуумлбмюрнуеоьеемает ещтремлбобьсемйчщнбмгртвмйрьеаьрмвмьсаепрмьемрфекбц\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYaagnpTA4FE"
      },
      "source": [
        "#### Observations\n",
        "Once we went to n_gram = 3 we got better results, but with higher n_grams our results became very bad. But then once I increase number of iterations I got almost perfect result for n_gram=4. However, n_gram=5 didn't converge even after 1,000,000 iterations. Higher n_grams can give good results but they require significantly larger number of iterations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65eXYDqQBunY"
      },
      "source": [
        "## 5. Applications of MCMC decoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW7TLBV1BzJl"
      },
      "source": [
        "1. Maybe one possible use can be in compression/decompression of the files. Mapping between small and big chunks of data can be made. As a result small chunk of data can be sent and then on the receiver side the small chunk of data can be decoded into bigger chunk.\n",
        "2. Another application maybe in genomics. Mapping between certain genetic DNA sequences that can be decoded to certain traits of an organism.\n"
      ]
    }
  ]
}