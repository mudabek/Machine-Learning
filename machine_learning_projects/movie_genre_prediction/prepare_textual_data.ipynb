{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Kernel notebook for cleaning up the textual data for model building purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports ####\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.pyplot.style.use('ggplot')\n",
    "\n",
    "from sklearn import datasets, linear_model, metrics, model_selection, pipeline, preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import custom extended stop words, train and test data ###\n",
    "\n",
    "with open('stoppers.txt', encoding = 'utf-8') as f:\n",
    "    stoppers = f.readlines()\n",
    "    \n",
    "stoppers = [x.strip() for x in stoppers]\n",
    "\n",
    "stopwords_new = stopwords.words('english')\n",
    "\n",
    "for word in stoppers:\n",
    "    stopwords_new.append(word)\n",
    "    \n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for cleaning data ###\n",
    "\n",
    "def remove_html(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    html_free = soup.get_text()\n",
    "    return html_free\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    no_punct = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    return no_punct\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords_new]\n",
    "    return words\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def word_lemmatizer(text):\n",
    "    lem_text = [lemmatizer.lemmatize(i) for i in text]\n",
    "    return lem_text\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def word_stemmer(text):\n",
    "    stem_text = \" \".join([stemmer.stem(i) for i in text])\n",
    "    return stem_text\n",
    "\n",
    "def process_arg(x : str):\n",
    "    x = x[1:-1]\n",
    "    x = x.replace(\"u\\'\", \"\")\n",
    "    x = x.replace(\"\\'\", \"\")\n",
    "    #l = x.split(',')\n",
    "    #x = l[0]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clean dialogue text ###\n",
    "\n",
    "train_data['dialogue'] = train_data['dialogue'].apply(lambda x: remove_html(x))\n",
    "train_data['dialogue'] = train_data['dialogue'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "train_data['dialogue'] = train_data['dialogue'].apply(lambda x: remove_stopwords(x))\n",
    "train_data['dialogue'] = train_data['dialogue'].apply(lambda x: word_stemmer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clean genres ###\n",
    "\n",
    "train_data['genres'] = train_data['genres'].apply(lambda x: process_arg(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clean test text ###\n",
    "\n",
    "test_data['dialogue'] = test_data['dialogue'].apply(lambda x: remove_html(x))\n",
    "test_data['dialogue'] = test_data['dialogue'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "test_data['dialogue'] = test_data['dialogue'].apply(lambda x: remove_stopwords(x))\n",
    "test_data['dialogue'] = test_data['dialogue'].apply(lambda x: word_stemmer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export data ###\n",
    "\n",
    "train_data.to_csv('clean_train_stem.csv', index=False)\n",
    "test_data.to_csv('clean_test_stem.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
