{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4507,
     "status": "ok",
     "timestamp": 1608703172769,
     "user": {
      "displayName": "Otabek Nazarov",
      "photoUrl": "",
      "userId": "10368252367440288933"
     },
     "user_tz": -240
    },
    "id": "XVMIWvDkp_x8"
   },
   "outputs": [],
   "source": [
    "### Imports ###\n",
    "\n",
    "import os, shutil\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4431,
     "status": "ok",
     "timestamp": 1608703172771,
     "user": {
      "displayName": "Otabek Nazarov",
      "photoUrl": "",
      "userId": "10368252367440288933"
     },
     "user_tz": -240
    },
    "id": "G4wB5akonwzA",
    "outputId": "aa210405-1c82-43e2-ba1d-d895f679feb2"
   },
   "outputs": [],
   "source": [
    "### Connect to a google drive ###\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "ROOT = '/content/drive/MyDrive/Colab_Notebooks/cats_vs_dogs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeUN0imKo-rW"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8xpfPLKmvyD"
   },
   "source": [
    "This section of notebook prepares data for training and testing and predicting purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 692,
     "status": "ok",
     "timestamp": 1608703253213,
     "user": {
      "displayName": "Otabek Nazarov",
      "photoUrl": "",
      "userId": "10368252367440288933"
     },
     "user_tz": -240
    },
    "id": "VJg4pi50dP5Q"
   },
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "\n",
    "    # override the __getitem__ method. this is the method that dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 92618,
     "status": "ok",
     "timestamp": 1608703775038,
     "user": {
      "displayName": "Otabek Nazarov",
      "photoUrl": "",
      "userId": "10368252367440288933"
     },
     "user_tz": -240
    },
    "id": "8SB3AdAzuBB9",
    "outputId": "92054c01-ef67-47fa-eb88-978867b1b922"
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "img_dimensions = 224\n",
    "num_workers = 6\n",
    "\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_dimensions, img_dimensions)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n",
    "img_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_dimensions,img_dimensions)),    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n",
    "img_aug_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_dimensions, img_dimensions)),\n",
    "    transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20, resample=PIL.Image.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n",
    "def check_image(path):\n",
    "    try:\n",
    "        im = Image.open(path)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "test_200_path = ROOT + \"test_200\"\n",
    "test_200_data = ImageFolderWithPaths(root=test_200_path,transform=img_transforms, is_valid_file=check_image)\n",
    "torch.save(test_200_data, ROOT + \"test_200_with_filepath.pt\")\n",
    "test_200_data = torch.load(ROOT + \"test_200_with_filepath.pt\")\n",
    "test_200_loader = torch.utils.data.DataLoader(test_200_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# final_test_data_path = \"/content/drive/MyDrive/Colab_Notebooks/cats_vs_dogs/finat_test\"\n",
    "# final_test_data = ImageFolderWithPaths(root=final_test_data_path,transform=img_transforms, is_valid_file=check_image)\n",
    "# torch.save(final_test_data, \"/content/drive/MyDrive/Colab_Notebooks/cats_vs_dogs/test_data_with_filepath.pt\")\n",
    "# final_test_data = torch.load(\"/content/drive/MyDrive/Colab_Notebooks/cats_vs_dogs/test_data_with_filepath.pt\")\n",
    "\n",
    "# train_data_path = \"/content/drive/MyDrive/Colab_Notebooks/cats_vs_dogs/train/\"\n",
    "# train_data = torchvision.datasets.ImageFolder(root=train_data_path,transform=img_transforms, is_valid_file=check_image)\n",
    "# torch.save(train_data, \"/content/drive/MyDrive/Colab_Notebooks/cats_vs_dogs/train_og.pt\")\n",
    "# train_data = torch.load(\"/content/drive/MyDrive/Colab_Notebooks/cats_vs_dogs/train_og.pt\")\n",
    "\n",
    "# validation_data_path = \"/content/drive/MyDrive/Colab_Notebooks/cats_vs_dogs/validation/\"\n",
    "# validation_data = torchvision.datasets.ImageFolder(root=validation_data_path,transform=img_test_transforms, is_valid_file=check_image)\n",
    "# torch.save(validation_data, \"/content/drive/MyDrive/Colab_Notebooks/cats_vs_dogs/validation_og.pt\")\n",
    "# validation_data = torch.load(\"/content/drive/MyDrive/Colab_Notebooks/cats_vs_dogs/validation_og.pt\")\n",
    "\n",
    "# test_data_path = \"/content/drive/MyDrive/Colab_Notebooks/cats_vs_dogs/test/\"\n",
    "# test_data = torchvision.datasets.ImageFolder(root=test_data_path,transform=img_test_transforms, is_valid_file=check_image)\n",
    "# torch.save(test_data, \"/content/drive/MyDrive/Colab_Notebooks/cats_vs_dogs/test_og.pt\")\n",
    "# test_data = torch.load(\"/content/drive/MyDrive/Colab_Notebooks/cats_vs_dogs/test_og.pt\")\n",
    "\n",
    "# full_data_path = \"/content/drive/MyDrive/Colab_Notebooks/cats_vs_dogs/full/\"\n",
    "# full_data = torchvision.datasets.ImageFolder(root=full_data_path,transform=img_test_transforms, is_valid_file=check_image)\n",
    "# torch.save(full_data, \"/content/drive/MyDrive/Colab_Notebooks/cats_vs_dogs/full_data_with_paths.pt\")\n",
    "# full_data = torch.load(\"/content/drive/MyDrive/Colab_Notebooks/cats_vs_dogs/full_data_with_paths.pt\")\n",
    "\n",
    "\n",
    "# num_workers = 6\n",
    "# train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "# validation_data_loader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "# test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "# final_test_data_loader = torch.utils.data.DataLoader(final_test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "# full_data_loader = torch.utils.data.DataLoader(full_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgMnnTAFtAE8"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgFu211Om5CF"
   },
   "source": [
    "In this section we train different resnet models on a given dataset and save those models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHo16v6Rs_IA"
   },
   "outputs": [],
   "source": [
    "model_resnet18 = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n",
    "model_resnet34 = torch.hub.load('pytorch/vision', 'resnet34', pretrained=True)\n",
    "model_resnet101 = torch.hub.load('pytorch/vision', 'resnet101', pretrained=True)\n",
    "model_resnet152 = torch.hub.load('pytorch/vision', 'resnet152', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vRxpx2BwtEvq"
   },
   "outputs": [],
   "source": [
    "for name, param in model_resnet18.named_parameters():\n",
    "    if(\"bn\" not in name):\n",
    "        param.requires_grad = False\n",
    "        \n",
    "for name, param in model_resnet34.named_parameters():\n",
    "    if(\"bn\" not in name):\n",
    "        param.requires_grad = False\n",
    "\n",
    "for name, param in model_resnet101.named_parameters():\n",
    "    if(\"bn\" not in name):\n",
    "        param.requires_grad = False\n",
    "\n",
    "for name, param in model_resnet152.named_parameters():\n",
    "    if(\"bn\" not in name):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qaIMByKGtGw6"
   },
   "outputs": [],
   "source": [
    "# replace the classifier to get two outputs only\n",
    "num_classes = 2\n",
    "\n",
    "model_resnet18.fc = nn.Sequential(nn.Linear(model_resnet18.fc.in_features,512),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(),\n",
    "                                  nn.Linear(512, num_classes))\n",
    "\n",
    "model_resnet34.fc = nn.Sequential(nn.Linear(model_resnet34.fc.in_features,512),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(),\n",
    "                                  nn.Linear(512, num_classes))\n",
    "\n",
    "model_resnet101.fc = nn.Sequential(nn.Linear(model_resnet101.fc.in_features,512),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(),\n",
    "                                  nn.Linear(512, num_classes))\n",
    "\n",
    "model_resnet152.fc = nn.Sequential(nn.Linear(model_resnet152.fc.in_features,512),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(),\n",
    "                                  nn.Linear(512, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 767,
     "status": "ok",
     "timestamp": 1608703261787,
     "user": {
      "displayName": "Otabek Nazarov",
      "photoUrl": "",
      "userId": "10368252367440288933"
     },
     "user_tz": -240
    },
    "id": "BMCZGFQ76j7K"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVtLNqR4tK0S"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=5, device=\"cpu\"):\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item() * inputs.size(0)\n",
    "        training_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        num_correct = 0 \n",
    "        num_examples = 0\n",
    "        for batch in val_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "            targets = targets.to(device)\n",
    "            loss = loss_fn(output,targets) \n",
    "            valid_loss += loss.data.item() * inputs.size(0)\n",
    "                        \n",
    "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "        valid_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}, accuracy = {:.4f}'.format(epoch, training_loss,\n",
    "        valid_loss, num_correct / num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U_sqg1rsu4Bh"
   },
   "outputs": [],
   "source": [
    "model_resnet34.to(device)\n",
    "optimizer = optim.Adam(model_resnet34.parameters(), lr=0.001)\n",
    "train(model_resnet34, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, validation_data_loader, epochs=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5PeK8X3vEym"
   },
   "outputs": [],
   "source": [
    "model_resnet18.to(device)\n",
    "optimizer = optim.Adam(model_resnet18.parameters(), lr=0.001)\n",
    "train(model_resnet18, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, validation_data_loader, epochs=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8u3pQra5Pgz"
   },
   "outputs": [],
   "source": [
    "model_resnet101.to(device)\n",
    "optimizer = optim.Adam(model_resnet101.parameters(), lr=0.001)\n",
    "train(model_resnet101, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, validation_data_loader, epochs=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5JoMM7fhQn3C"
   },
   "outputs": [],
   "source": [
    "model_resnet152.to(device)\n",
    "optimizer = optim.Adam(model_resnet152.parameters(), lr=0.001)\n",
    "train(model_resnet152, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, validation_data_loader, epochs=10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38ljExrofdh8"
   },
   "outputs": [],
   "source": [
    "# torch.save(model_resnet18.state_dict(), \"/content/drive/MyDrive/Colab_Notebooks/cats_vs_dogs/state_dict_resnet18.pt\")\n",
    "# torch.save(model_resnet34.state_dict(), \"/content/drive/MyDrive/Colab_Notebooks/cats_vs_dogs/state_dict_resnet34.pt\")\n",
    "# torch.save(model_resnet101.state_dict(), \"/content/drive/MyDrive/Colab_Notebooks/cats_vs_dogs/state_dict_resnet101.pt\")\n",
    "# torch.save(model_resnet152.state_dict(), \"/content/drive/MyDrive/Colab_Notebooks/cats_vs_dogs/state_dict_resnet152.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBFPRnhXile8"
   },
   "outputs": [],
   "source": [
    "### Load all saved models ###\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "resnet18 = torch.hub.load('pytorch/vision', 'resnet18')\n",
    "resnet18.fc = nn.Sequential(nn.Linear(resnet18.fc.in_features,512),nn.ReLU(), nn.Dropout(), nn.Linear(512, num_classes))\n",
    "resnet18.load_state_dict(torch.load(ROOT + \"state_dict_resnet18.pt\"))\n",
    "resnet18.eval()\n",
    "\n",
    "resnet34 = torch.hub.load('pytorch/vision', 'resnet34')\n",
    "resnet34.fc = nn.Sequential(nn.Linear(resnet34.fc.in_features,512),nn.ReLU(), nn.Dropout(), nn.Linear(512, num_classes))\n",
    "resnet34.load_state_dict(torch.load(ROOT + \"state_dict_resnet34.pt\"))\n",
    "resnet34.eval()\n",
    "\n",
    "resnet50 = torch.hub.load('pytorch/vision', 'resnet50')\n",
    "resnet50.fc = nn.Sequential(nn.Linear(resnet50.fc.in_features,512),nn.ReLU(), nn.Dropout(), nn.Linear(512, num_classes))\n",
    "resnet50.load_state_dict(torch.load(ROOT + \"state_dict_resnet50.pt\"))\n",
    "resnet50.eval()\n",
    "\n",
    "resnet101 = torch.hub.load('pytorch/vision', 'resnet101')\n",
    "resnet101.fc = nn.Sequential(nn.Linear(resnet101.fc.in_features,512),nn.ReLU(), nn.Dropout(), nn.Linear(512, num_classes))\n",
    "resnet101.load_state_dict(torch.load(ROOT + \"state_dict_resnet101.pt\"))\n",
    "resnet101.eval()\n",
    "\n",
    "resnet152 = torch.hub.load('pytorch/vision', 'resnet152')\n",
    "resnet152.fc = nn.Sequential(nn.Linear(resnet152.fc.in_features,512),nn.ReLU(), nn.Dropout(), nn.Linear(512, num_classes))\n",
    "resnet152.load_state_dict(torch.load(ROOT + \"state_dict_resnet152.pt\"))\n",
    "resnet152.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0J0gqgT2pFyB"
   },
   "source": [
    "# Output test results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AH5urQcGniyr"
   },
   "source": [
    "Here we export the results of our models for predictions on 25000 and 12500 cats and dogs pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 680,
     "status": "ok",
     "timestamp": 1608703804437,
     "user": {
      "displayName": "Otabek Nazarov",
      "photoUrl": "",
      "userId": "10368252367440288933"
     },
     "user_tz": -240
    },
    "id": "DlgZlXgVk3Hf"
   },
   "outputs": [],
   "source": [
    "models = [resnet34, resnet50, resnet101, resnet152]\n",
    "filenames = ['200_resnet34.csv', '200_resnet50.csv', '200_resnet101.csv', '200_resnet152.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1608703809122,
     "user": {
      "displayName": "Otabek Nazarov",
      "photoUrl": "",
      "userId": "10368252367440288933"
     },
     "user_tz": -240
    },
    "id": "2Ng-hdoUnTnY"
   },
   "outputs": [],
   "source": [
    "# function to export human sorted pandas framework\n",
    "\n",
    "def export_human_sorted_df(df, filename):\n",
    "  df['column'] = df.path.str.extract('(\\d+)')\n",
    "  df['column'] = pd.to_numeric(df['column'])\n",
    "  df.sort_values(by=['column']).to_csv(ROOT + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1608703819753,
     "user": {
      "displayName": "Otabek Nazarov",
      "photoUrl": "",
      "userId": "10368252367440288933"
     },
     "user_tz": -240
    },
    "id": "jS8ZQlFrzGBV"
   },
   "outputs": [],
   "source": [
    "# function to check through the tests and save data \n",
    "def test_model(models, loader, filepaths):\n",
    "  for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    filepath = filepaths[i]\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pd_result = pd.DataFrame([])\n",
    "    pd_paths = pd.DataFrame([])\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels, paths = data[0].to(device), data[1].to(device), list(data[2])\n",
    "            outputs = model(images)\n",
    "            pd_result = pd_result.append(outputs.tolist(), ignore_index=True)\n",
    "            pd_paths = pd_paths.append(paths, ignore_index=True) \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    # export results\n",
    "    merge = pd.concat([pd_result, pd_paths], axis=1)\n",
    "    merge.columns = ['0', '1', 'path']\n",
    "    for i in merge.index:\n",
    "      merge.at[i, 'path'] = merge.at[i, 'path'].split('/')[-1]\n",
    "    export_human_sorted_df(merge, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37784,
     "status": "ok",
     "timestamp": 1608703859990,
     "user": {
      "displayName": "Otabek Nazarov",
      "photoUrl": "",
      "userId": "10368252367440288933"
     },
     "user_tz": -240
    },
    "id": "kkIW1iv5ixWz",
    "outputId": "a7b76d45-ae60-4da9-d79c-9e9c4efc9e69"
   },
   "outputs": [],
   "source": [
    "test_model(models, test_200_loader, filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24FSOIDM4vLA"
   },
   "source": [
    "# Average Ensemble "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCavmRGKn6dq"
   },
   "source": [
    "In this section we tried to experiment and see what we get if we try to ensemble the models thru averaging their outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8382,
     "status": "ok",
     "timestamp": 1608703875425,
     "user": {
      "displayName": "Otabek Nazarov",
      "photoUrl": "",
      "userId": "10368252367440288933"
     },
     "user_tz": -240
    },
    "id": "Q0hUaUKE5S7w",
    "outputId": "118927a5-6e38-45b9-fb24-2e304688e9c6"
   },
   "outputs": [],
   "source": [
    "### Average of resnet18 and resnet34 ###\n",
    "\n",
    "models_ensemble = [resnet18.to(device), resnet34.to(device)]\n",
    "correct = 0\n",
    "total = 0\n",
    "ensem_result = pd.DataFrame([])\n",
    "ensem_paths = pd.DataFrame([])\n",
    "with torch.no_grad():\n",
    "    for data in test_200_loader:\n",
    "        images, labels, paths = data[0].to(device), data[1].to(device), list(data[2])\n",
    "        predictions = [i(images).data for i in models_ensemble]\n",
    "        avg_predictions = torch.mean(torch.stack(predictions), dim=0)\n",
    "        ensem_result = ensem_result.append(avg_predictions.tolist(), ignore_index=True)\n",
    "        ensem_paths = ensem_paths.append(paths, ignore_index=True) \n",
    "        _, predicted = torch.max(avg_predictions, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1250,
     "status": "ok",
     "timestamp": 1608703880265,
     "user": {
      "displayName": "Otabek Nazarov",
      "photoUrl": "",
      "userId": "10368252367440288933"
     },
     "user_tz": -240
    },
    "id": "h2fTHN237q5z"
   },
   "outputs": [],
   "source": [
    "merged = pd.concat([ensem_result, ensem_paths], axis=1)\n",
    "merged.columns = ['0', '1', 'path']\n",
    "for i in merged.index:\n",
    "  merged.at[i, 'path'] = merged.at[i, 'path'].split('/')[-1]\n",
    "\n",
    "export_human_sorted_df(merged, '200_resnet_18_34.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNJovTvWx8EaObjSZRZbe4R",
   "collapsed_sections": [],
   "mount_file_id": "15zKAUUY0gibV8D4V2Vaj2qAU3FZE6r_j",
   "name": "cats_and_dogs_training",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
